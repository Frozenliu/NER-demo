{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "word_input (InputLayer)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "word_embedding (Embedding)   (None, 100, 100)          519800    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "BiLSTM (Bidirectional)       (None, 100, 120)          212160    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 100, 100)          12100     \n",
      "_________________________________________________________________\n",
      "crf (CRF)                    (None, 100, 8)            888       \n",
      "=================================================================\n",
      "Total params: 744,948\n",
      "Trainable params: 744,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 298770 samples, validate on 13004 samples\n",
      "Epoch 1/15\n",
      "298770/298770 [==============================] - 3947s 13ms/step - loss: 21.4262 - acc: 0.9582 - val_loss: 21.8643 - val_acc: 0.9670\n",
      "Epoch 2/15\n",
      "298770/298770 [==============================] - 3938s 13ms/step - loss: 21.3849 - acc: 0.9709 - val_loss: 21.8549 - val_acc: 0.9742\n",
      "Epoch 3/15\n",
      "298770/298770 [==============================] - 3936s 13ms/step - loss: 21.3798 - acc: 0.9748 - val_loss: 21.8553 - val_acc: 0.9739\n",
      "Epoch 4/15\n",
      "298770/298770 [==============================] - 3936s 13ms/step - loss: 21.3771 - acc: 0.9769 - val_loss: 21.8535 - val_acc: 0.9742\n",
      "Epoch 5/15\n",
      "298770/298770 [==============================] - 3935s 13ms/step - loss: 21.3754 - acc: 0.9784 - val_loss: 21.8517 - val_acc: 0.9758\n",
      "Epoch 6/15\n",
      "298770/298770 [==============================] - 3936s 13ms/step - loss: 21.3742 - acc: 0.9796 - val_loss: 21.8503 - val_acc: 0.9784\n",
      "Epoch 7/15\n",
      "298770/298770 [==============================] - 3940s 13ms/step - loss: 21.3735 - acc: 0.9800 - val_loss: 21.8492 - val_acc: 0.9787\n",
      "Epoch 8/15\n",
      "298770/298770 [==============================] - 3972s 13ms/step - loss: 21.3728 - acc: 0.9805 - val_loss: 21.8509 - val_acc: 0.9783\n",
      "Epoch 9/15\n",
      "298770/298770 [==============================] - 3938s 13ms/step - loss: 21.3722 - acc: 0.9810 - val_loss: 21.8541 - val_acc: 0.9743\n",
      "Epoch 10/15\n",
      "298770/298770 [==============================] - 3940s 13ms/step - loss: 21.3719 - acc: 0.9814 - val_loss: 21.8516 - val_acc: 0.9778\n",
      "Epoch 11/15\n",
      "298770/298770 [==============================] - 3940s 13ms/step - loss: 21.3717 - acc: 0.9814 - val_loss: 21.8515 - val_acc: 0.9777\n",
      "Epoch 12/15\n",
      "298770/298770 [==============================] - 3940s 13ms/step - loss: 21.3714 - acc: 0.9817 - val_loss: 21.8501 - val_acc: 0.9795\n",
      "Epoch 13/15\n",
      "298770/298770 [==============================] - 3940s 13ms/step - loss: 21.3713 - acc: 0.9819 - val_loss: 21.8519 - val_acc: 0.9761\n",
      "Epoch 14/15\n",
      "298770/298770 [==============================] - 3939s 13ms/step - loss: 21.3710 - acc: 0.9820 - val_loss: 21.8499 - val_acc: 0.9799\n",
      "Epoch 15/15\n",
      "298770/298770 [==============================] - 3937s 13ms/step - loss: 21.3708 - acc: 0.9821 - val_loss: 21.8506 - val_acc: 0.9802\n",
      "0.9757258474303675\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          O      0.985     0.996     0.990    152505\n",
      "      B-LOC      0.929     0.831     0.877      2877\n",
      "      I-LOC      0.913     0.861     0.887      4394\n",
      "      B-ORG      0.889     0.703     0.785      1331\n",
      "      I-ORG      0.906     0.803     0.852      5670\n",
      "      B-PER      0.948     0.735     0.828      1973\n",
      "      I-PER      0.863     0.930     0.895      3851\n",
      "\n",
      "avg / total      0.976     0.976     0.976    172601\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from model import BiLSTM_crf\n",
    "from utils import load_data_and_labels,save_pred,transformer_x,transformer_y\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "x_train, y_train = load_data_and_labels('../data/train.txt')\n",
    "transformer_x = transformer_x()\n",
    "x_train = transformer_x.fit(x_train)\n",
    "vocab_size = transformer_x.vocab_size\n",
    "transformer_y = transformer_y(transformer_x.max_len)\n",
    "y_train = transformer_y.to_onehot(y_train)\n",
    "\n",
    "use_crf = True\n",
    "model = BiLSTM_crf(num_labels=8, word_vocab_size = vocab_size,max_seq_len=transformer_x.max_len,use_crf = use_crf)\n",
    "model = model.build()\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# model.fit(x_train,y_train,verbose = 1,batch_size = 12,epochs= 1)\n",
    "x_test, y_test = load_data_and_labels('../data/dev.txt')\n",
    "x_test = transformer_x.tran(x_test)\n",
    "y_test_onehot = transformer_y.to_onehot(y_test)\n",
    "model.fit(x_train,y_train,validation_data = (x_test,y_test_onehot),verbose = 1,epochs= 15)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "pred = transformer_y.to_tag(pred)\n",
    "print(metrics.flat_f1_score(y_test, pred,\n",
    "                      average='weighted', labels=transformer_y.tags))\n",
    "\n",
    "# group B and I results\n",
    "labels = transformer_y.tags\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, pred, labels=sorted_labels, digits=3\n",
    "))\n",
    "save_pred(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC      0.929     0.831     0.877      2877\n",
      "      I-LOC      0.913     0.861     0.887      4394\n",
      "      B-ORG      0.889     0.703     0.785      1331\n",
      "      I-ORG      0.906     0.803     0.852      5670\n",
      "      B-PER      0.948     0.735     0.828      1973\n",
      "      I-PER      0.863     0.930     0.895      3851\n",
      "\n",
      "avg / total      0.906     0.831     0.865     20096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels.remove('O')\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只跑一个epoch，模型将所有tag都预测为‘O’，这是可以理解的，在没有得到足够的训练的情况下，这种保守的预测可以得到较高的crf.accuracy；在之后的训练中，想得到更高的accuracy就必须改变保守的策略，从而会预测出entity。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir('../data/15epochs')\n",
    "model.save('../data/15epochs/15epochs_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5198"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_x.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_x.max_len"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
